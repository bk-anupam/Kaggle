{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from optuna.integration.lightgbm import LightGBMTunerCV, LightGBMTuner\n",
    "import category_encoders\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"song_popularity\"\n",
    "    CATEGORICAL_COLS = [\"key\", \"audio_mode\", \"time_signature\"]\n",
    "    EARLY_STOPPING = 500\n",
    "    RESULTS_FILE = \"model_execution_results.pkl\"\n",
    "    MODEL = \"LGBM\"\n",
    "\n",
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the train data into k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>audio_mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>audio_valence</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32823</td>\n",
       "      <td>144667.0</td>\n",
       "      <td>0.585599</td>\n",
       "      <td>0.691626</td>\n",
       "      <td>0.503891</td>\n",
       "      <td>0.222360</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.115524</td>\n",
       "      <td>-11.642316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>86.041825</td>\n",
       "      <td>3</td>\n",
       "      <td>0.539072</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16298</td>\n",
       "      <td>203954.0</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.667695</td>\n",
       "      <td>0.683820</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102933</td>\n",
       "      <td>97.073546</td>\n",
       "      <td>3</td>\n",
       "      <td>0.667166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28505</td>\n",
       "      <td>179054.0</td>\n",
       "      <td>0.069471</td>\n",
       "      <td>0.624358</td>\n",
       "      <td>0.891436</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173795</td>\n",
       "      <td>140.102334</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6689</td>\n",
       "      <td>246074.0</td>\n",
       "      <td>0.333662</td>\n",
       "      <td>0.645299</td>\n",
       "      <td>0.716589</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.114810</td>\n",
       "      <td>-9.178056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>101.694474</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532739</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26893</td>\n",
       "      <td>282403.0</td>\n",
       "      <td>0.378221</td>\n",
       "      <td>0.258557</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.172308</td>\n",
       "      <td>-6.721257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044904</td>\n",
       "      <td>123.402262</td>\n",
       "      <td>3</td>\n",
       "      <td>0.717549</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  song_duration_ms  acousticness  danceability    energy  \\\n",
       "0  32823          144667.0      0.585599      0.691626  0.503891   \n",
       "1  16298          203954.0      0.016664      0.667695  0.683820   \n",
       "2  28505          179054.0      0.069471      0.624358  0.891436   \n",
       "3   6689          246074.0      0.333662      0.645299  0.716589   \n",
       "4  26893          282403.0      0.378221      0.258557  0.617000   \n",
       "\n",
       "   instrumentalness   key  liveness   loudness  audio_mode  speechiness  \\\n",
       "0          0.222360  10.0  0.115524 -11.642316           0     0.049854   \n",
       "1          0.001178   4.0  0.213299        NaN           1     0.102933   \n",
       "2          0.000637   2.0       NaN        NaN           1     0.173795   \n",
       "3          0.003159   2.0  0.114810  -9.178056           0     0.056690   \n",
       "4          0.001366   7.0  0.172308  -6.721257           0     0.044904   \n",
       "\n",
       "        tempo  time_signature  audio_valence  song_popularity  kfold  \n",
       "0   86.041825               3       0.539072                1      4  \n",
       "1   97.073546               3       0.667166                0      0  \n",
       "2  140.102334               4       0.824423                0      1  \n",
       "3  101.694474               4       0.532739                1      3  \n",
       "4  123.402262               3       0.717549                0      1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_SEED)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold    \n",
    "    return df     \n",
    "\n",
    "df_train = strat_kfold_dataframe(df_train, target_col_name=Config.TARGET_COL_NAME, num_folds=Config.NUM_FOLDS)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['song_duration_ms', 'acousticness', 'danceability', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'audio_valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creater marker columns for missing values <br>\n",
    "Hoping it provides more signal to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_col(df, cols_with_nulls):\n",
    "    for col_name in cols_with_nulls:        \n",
    "        df[col_name + \"_missing\"] = [int(item) for item in df[col_name].isna().values]\n",
    "    return df        \n",
    "\n",
    "train_cols_withnulls = [col for col in df_train.columns if df_train[col].isnull().any()]\n",
    "test_cols_withnulls = [col for col in df_test.columns if df_test[col].isnull().any()]\n",
    "df_train = add_missing_col(df_train, train_cols_withnulls)\n",
    "df_test = add_missing_col(df_test, test_cols_withnulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use \"mean\" imputing strategy for continuous and \"most frequent\" for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df_col(df, col_name, imputer):\n",
    "    imputed_col = imputer.fit_transform(df[col_name].to_numpy().reshape(-1, 1))\n",
    "    return pd.Series(imputed_col.reshape(-1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df, cols, col_type=\"cont\"):    \n",
    "    if col_type == \"cont\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    elif col_type == \"cat\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")            \n",
    "    for col in cols:\n",
    "        df[col] = impute_df_col(df, col, imputer)\n",
    "    return df\n",
    "\n",
    "df_train = impute_missing_values(df_train, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_train = impute_missing_values(df_train, cont_cols, col_type=\"cont\")\n",
    "df_test = impute_missing_values(df_test, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_test = impute_missing_values(df_test, cont_cols, col_type=\"cont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical column encoding (one hot) using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, prefix=Config.CATEGORICAL_COLS, columns=Config.CATEGORICAL_COLS)\n",
    "df_test = pd.get_dummies(df_test, prefix=Config.CATEGORICAL_COLS, columns=Config.CATEGORICAL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_int_encoding(df, col_name):\n",
    "    ordinal_encoder = category_encoders.OrdinalEncoder(cols=[col_name])\n",
    "    col_encoded = ordinal_encoder.fit_transform(df[col_name])\n",
    "    return col_encoded.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"key\"] = col_int_encoding(df_train, \"key\")\n",
    "# df_test[\"key\"] = col_int_encoding(df_test, \"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train[\"key\"].dtype)\n",
    "# print(df_test[\"key\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_leave = [\"id\", \"kfold\", \"song_popularity_proba\", Config.TARGET_COL_NAME]\n",
    "col_names = [item for item in df_train.columns.values.tolist() if item not in cols_to_leave]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_data(fold, df):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]    \n",
    "    X_train = df_train[col_names]\n",
    "    y_train = df_train[Config.TARGET_COL_NAME]\n",
    "    X_val = df_val[col_names]\n",
    "    y_val = df_val[Config.TARGET_COL_NAME]\n",
    "    return X_train, y_train, X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_df, train_y, val_df, val_y, params=None, callbacks=None):\n",
    "    train_data = lgbm.Dataset(\n",
    "            data=train_df[col_names], label=train_y, feature_name=col_names#, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS\n",
    "        )\n",
    "    val_data = lgbm.Dataset(\n",
    "            data=val_df[col_names], label=val_y, feature_name=col_names, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS, \n",
    "            reference=train_data\n",
    "        )    \n",
    "    if callbacks is not None:        \n",
    "        model = lgbm.train(\n",
    "                    params,\n",
    "                    train_set=train_data,                \n",
    "                    valid_sets=val_data,\n",
    "                    verbose_eval=-1,\n",
    "                    callbacks=callbacks\n",
    "                )\n",
    "    else:\n",
    "        model = lgbm.train(\n",
    "                    params,\n",
    "                    train_set=train_data,                \n",
    "                    valid_sets=val_data,\n",
    "                    verbose_eval=-1\n",
    "                )       \n",
    "    val_preds = model.predict(val_df, num_iteration=model.best_iteration)    \n",
    "    auc = roc_auc_score(val_y, val_preds)\n",
    "    return auc, val_preds, model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params(train_df, train_y, params=None):\n",
    "    train_data = lgbm.Dataset(\n",
    "            data=train_df[col_names], label=train_y, feature_name=col_names#, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS\n",
    "        )   \n",
    "    lgbmtuner_cv = LightGBMTunerCV(\n",
    "        params,\n",
    "        train_set=train_data,        \n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        nfold=Config.NUM_FOLDS,\n",
    "        verbose_eval=-1\n",
    "    ) \n",
    "    lgbmtuner_cv.run()                \n",
    "    print(\"Best Params: \", lgbmtuner_cv.best_params)    \n",
    "    print(\"Best score: \", lgbmtuner_cv.best_score)    \n",
    "    return lgbmtuner_cv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you want to run tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"auc\",\n",
    "#         \"verbosity\": -1,\n",
    "#         \"boosting_type\": \"gbdt\",\n",
    "#     }\n",
    "\n",
    "# train_y = df_train[Config.TARGET_COL_NAME]\n",
    "# tuned_model = tune_params(df_train, train_y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params1 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbosity': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 3.5832756412408226e-05, \n",
    "    'lambda_l2': 7.499744130226807, \n",
    "    'num_leaves': 2, \n",
    "    'feature_fraction': 0.8, \n",
    "    'bagging_fraction': 0.9969384880158432, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 20, \n",
    "    'num_iterations': 1000, \n",
    "    'early_stopping_round': None, \n",
    "    'categorical_column': [5, 8, 11]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMTunerCV with 5 folds\n",
    "model_params3 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 7.994567596327698, \n",
    "    'lambda_l2': 0.04882156030098934, \n",
    "    'num_leaves': 2, \n",
    "    'feature_fraction': 0.48000000000000004, \n",
    "    'bagging_fraction': 0.957852828579762, \n",
    "    'bagging_freq': 5, \n",
    "    'min_child_samples': 100,\n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning with LightGBMTunerCV\n",
    "\n",
    "model_params2 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 9.439044618205312, \n",
    "    'lambda_l2': 0.615750336486198, \n",
    "    'num_leaves': 3, \n",
    "    'feature_fraction': 0.62, \n",
    "    'bagging_fraction': 0.5286479709465361, \n",
    "    'bagging_freq': 1, \n",
    "    'min_child_samples': 20,    \n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 500\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params4 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 1.8963776746935667e-06, \n",
    "    'lambda_l2': 9.579973179083996, \n",
    "    'num_leaves': 3, \n",
    "    'feature_fraction': 0.7, \n",
    "    'bagging_fraction': 0.7684172265445463, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 20,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 500,\n",
    "    \"learning_rate\": 0.01\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[881]\tvalid_0's auc: 0.571597\n",
      "fold 0 auc score = 0.5715973699462203\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's auc: 0.571135\n",
      "fold 1 auc score = 0.5711349595470483\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's auc: 0.581001\n",
      "fold 2 auc score = 0.5810007235487282\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's auc: 0.580324\n",
      "fold 3 auc score = 0.5803238597361156\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid_0's auc: 0.576306\n",
      "fold 4 auc score = 0.5763063933710119\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = []\n",
    "test_preds = {}\n",
    "df_train[\"song_popularity_proba\"] = 0.0\n",
    "model_params=model_params2\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    train_df, train_y, val_df, val_y = get_fold_data(fold, df_train) \n",
    "    test_df = df_test[col_names]    \n",
    "    fold_auc_score, fold_val_preds, model = run_training(train_df, train_y, val_df, val_y, params=model_params)\n",
    "    print(f\"fold {fold } auc score = {fold_auc_score}\")\n",
    "    # add the validation probability predictions for the fold to a new column in train data\n",
    "    df_train.loc[df_train.kfold == fold, \"song_popularity_proba\"] = fold_val_preds    \n",
    "    fold_test_preds = model.predict(test_df, num_iteration=model.best_iteration)\n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds \n",
    "    fold_metrics_model.append((round(fold_auc_score, 6), model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross validation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc scores = [0.571597, 0.571135, 0.581001, 0.580324, 0.576306]\n",
      "mean auc across folds = 0.5760725999999999, auc stdev across folds = 0.0046591011257537595\n"
     ]
    }
   ],
   "source": [
    "fold_metrics = [item[0] for item in fold_metrics_model]\n",
    "print(f\"auc scores = {fold_metrics}\")    \n",
    "cv_auc_mean = statistics.mean(fold_metrics)\n",
    "cv_auc_stdev = statistics.stdev(fold_metrics)\n",
    "print(f\"mean auc across folds = {cv_auc_mean}, auc stdev across folds = {cv_auc_stdev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the results of the model training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(Config.RESULTS_FILE):\n",
    "    df_execution_results = pd.read_pickle(Config.RESULTS_FILE)\n",
    "else:\n",
    "    df_execution_results = pd.DataFrame({\n",
    "        \"model\": pd.Series(dtype=\"str\"),\n",
    "        \"fold_auc_scores\": pd.Series(dtype=\"object\"),\n",
    "        \"mean_auc\":pd.Series(dtype=\"float64\"),\n",
    "        \"auc_stdev\":pd.Series(dtype=\"float64\"),\n",
    "        \"model_params\": pd.Series(dtype=\"str\"),\n",
    "        \"input_features_used\": pd.Series(dtype=\"str\"),\n",
    "        \"Imputation\": pd.Series(dtype=\"bool\"),\n",
    "        \"Categorical_Encoding\": pd.Series(dtype=\"bool\")\n",
    "    })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold_auc_scores</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>auc_stdev</th>\n",
       "      <th>model_params</th>\n",
       "      <th>input_features_used</th>\n",
       "      <th>Imputation</th>\n",
       "      <th>Categorical_Encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>[0.583378, 0.571146, 0.586367, 0.580452, 0.596...</td>\n",
       "      <td>0.577996</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>[0.575174, 0.588837, 0.569445, 0.563312, 0.589...</td>\n",
       "      <td>0.578374</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM_RANDOMSEED_42</td>\n",
       "      <td>[0.573076, 0.548604, 0.598248, 0.582664, 0.567...</td>\n",
       "      <td>0.579745</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM_RANDOMSEED_13</td>\n",
       "      <td>[0.589234, 0.572599, 0.592026, 0.584541, 0.590...</td>\n",
       "      <td>0.579685</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM_RANDOMSEED_13</td>\n",
       "      <td>[0.587576, 0.569446, 0.589744, 0.583199, 0.587...</td>\n",
       "      <td>0.577720</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM_RANDOMSEED_2001</td>\n",
       "      <td>[0.571482, 0.600954, 0.575942, 0.572108, 0.585...</td>\n",
       "      <td>0.579771</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBM_RANDOMSEED_42</td>\n",
       "      <td>[0.606702, 0.589065, 0.624339, 0.616843, 0.566...</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBM_RANDOMSEED_42 OUTLIERS REMOVED</td>\n",
       "      <td>[0.578722, 0.584791, 0.579545, 0.573967, 0.568...</td>\n",
       "      <td>0.578720</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBM_RANDOMSEED_42 CONTINUOUS FEATURES OUTLIER...</td>\n",
       "      <td>[0.571509, 0.567632, 0.579917, 0.586348, 0.574...</td>\n",
       "      <td>0.579101</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBM_RANDOMSEED_42 CONTINUOUS FEATURES OUTLIER...</td>\n",
       "      <td>[0.571597, 0.571135, 0.581001, 0.580324, 0.576...</td>\n",
       "      <td>0.576073</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>{'objective': 'binary', 'metric': 'auc', 'verb...</td>\n",
       "      <td>[song_duration_ms, acousticness, danceability,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0                                               LGBM   \n",
       "1                                               LGBM   \n",
       "2                                 LGBM_RANDOMSEED_42   \n",
       "3                                 LGBM_RANDOMSEED_13   \n",
       "4                                 LGBM_RANDOMSEED_13   \n",
       "5                               LGBM_RANDOMSEED_2001   \n",
       "6                                 LGBM_RANDOMSEED_42   \n",
       "7                LGBM_RANDOMSEED_42 OUTLIERS REMOVED   \n",
       "8  LGBM_RANDOMSEED_42 CONTINUOUS FEATURES OUTLIER...   \n",
       "9  LGBM_RANDOMSEED_42 CONTINUOUS FEATURES OUTLIER...   \n",
       "\n",
       "                                     fold_auc_scores  mean_auc  auc_stdev  \\\n",
       "0  [0.583378, 0.571146, 0.586367, 0.580452, 0.596...  0.577996   0.009549   \n",
       "1  [0.575174, 0.588837, 0.569445, 0.563312, 0.589...  0.578374   0.009485   \n",
       "2  [0.573076, 0.548604, 0.598248, 0.582664, 0.567...  0.579745   0.011397   \n",
       "3  [0.589234, 0.572599, 0.592026, 0.584541, 0.590...  0.579685   0.008433   \n",
       "4  [0.587576, 0.569446, 0.589744, 0.583199, 0.587...  0.577720   0.009509   \n",
       "5  [0.571482, 0.600954, 0.575942, 0.572108, 0.585...  0.579771   0.013575   \n",
       "6  [0.606702, 0.589065, 0.624339, 0.616843, 0.566...  0.610147   0.068914   \n",
       "7  [0.578722, 0.584791, 0.579545, 0.573967, 0.568...  0.578720   0.011598   \n",
       "8  [0.571509, 0.567632, 0.579917, 0.586348, 0.574...  0.579101   0.008540   \n",
       "9  [0.571597, 0.571135, 0.581001, 0.580324, 0.576...  0.576073   0.004659   \n",
       "\n",
       "                                        model_params  \\\n",
       "0  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "1  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "2  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "3  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "4  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "5  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "6  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "7  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "8  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "9  {'objective': 'binary', 'metric': 'auc', 'verb...   \n",
       "\n",
       "                                 input_features_used  Imputation  \\\n",
       "0  [song_duration_ms, acousticness, danceability,...       False   \n",
       "1  [song_duration_ms, acousticness, danceability,...       False   \n",
       "2  [song_duration_ms, acousticness, danceability,...       False   \n",
       "3  [song_duration_ms, acousticness, danceability,...       False   \n",
       "4  [song_duration_ms, acousticness, danceability,...       False   \n",
       "5  [song_duration_ms, acousticness, danceability,...       False   \n",
       "6  [song_duration_ms, acousticness, danceability,...       False   \n",
       "7  [song_duration_ms, acousticness, danceability,...       False   \n",
       "8  [song_duration_ms, acousticness, danceability,...       False   \n",
       "9  [song_duration_ms, acousticness, danceability,...       False   \n",
       "\n",
       "   Categorical_Encoding  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "5                 False  \n",
       "6                 False  \n",
       "7                 False  \n",
       "8                 False  \n",
       "9                 False  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_results = pd.DataFrame({\n",
    "    \"model\": [Config.MODEL + \"_RANDOMSEED_\" + str(Config.RANDOM_SEED) + \" CONTINUOUS FEATURES OUTLIERS REMOVED\"],\n",
    "    \"fold_auc_scores\": [fold_metrics],\n",
    "    \"mean_auc\": [cv_auc_mean],\n",
    "    \"auc_stdev\": [cv_auc_stdev],\n",
    "    \"model_params\": [model_params],\n",
    "    \"input_features_used\": [col_names],\n",
    "    \"Imputation\": [False],\n",
    "    \"Categorical_Encoding\": [False]\n",
    "})\n",
    "model_execution_results = pd.concat([df_execution_results, execution_results], ignore_index=True)\n",
    "model_execution_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_execution_results.to_pickle(\"model_execution_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test set\n",
    "( Using \"average\" ensembling from the models returned by the training fold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 10000 test rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.447402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.270719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.288960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.367710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  song_popularity\n",
       "0   0         0.447402\n",
       "1   1         0.465931\n",
       "2   2         0.270719\n",
       "3   3         0.288960\n",
       "4   4         0.367710"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "test_pred_cols = [f\"fold_{fold}_test_preds\" for fold in range(Config.NUM_FOLDS)]\n",
    "df_test_preds[\"mean_test_pred\"] = df_test_preds[test_pred_cols].mean(axis=1)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")\n",
    "df_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "df_submission['song_popularity']= df_test_preds[\"mean_test_pred\"]\n",
    "df_submission.to_csv('submission_lgbm.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save OOF preds to csv (in case you want to use these for model blending later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation predictions for all folds to csv\n"
     ]
    }
   ],
   "source": [
    "lgbm_val_preds = df_train[[\"id\", \"song_popularity_proba\", \"song_popularity\"]]\n",
    "lgbm_val_preds.to_csv(\"lgbm_val_preds.csv\")\n",
    "print(\"Saved validation predictions for all folds to csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0197751694b00855cd01780d565fa2e16f7945f624c4146f8d6aac863c2ba178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
