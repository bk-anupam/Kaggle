{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from optuna.integration.lightgbm import LightGBMTunerCV, LightGBMTuner\n",
    "import category_encoders\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"song_popularity\"\n",
    "    CATEGORICAL_COLS = [\"key\", \"audio_mode\", \"time_signature\"]\n",
    "    EARLY_STOPPING = 500\n",
    "\n",
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>audio_mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>audio_valence</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32823</td>\n",
       "      <td>144667.0</td>\n",
       "      <td>0.585599</td>\n",
       "      <td>0.691626</td>\n",
       "      <td>0.503891</td>\n",
       "      <td>0.222360</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.115524</td>\n",
       "      <td>-11.642316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>86.041825</td>\n",
       "      <td>3</td>\n",
       "      <td>0.539072</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16298</td>\n",
       "      <td>203954.0</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.667695</td>\n",
       "      <td>0.683820</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102933</td>\n",
       "      <td>97.073546</td>\n",
       "      <td>3</td>\n",
       "      <td>0.667166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28505</td>\n",
       "      <td>179054.0</td>\n",
       "      <td>0.069471</td>\n",
       "      <td>0.624358</td>\n",
       "      <td>0.891436</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173795</td>\n",
       "      <td>140.102334</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6689</td>\n",
       "      <td>246074.0</td>\n",
       "      <td>0.333662</td>\n",
       "      <td>0.645299</td>\n",
       "      <td>0.716589</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.114810</td>\n",
       "      <td>-9.178056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>101.694474</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532739</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26893</td>\n",
       "      <td>282403.0</td>\n",
       "      <td>0.378221</td>\n",
       "      <td>0.258557</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.172308</td>\n",
       "      <td>-6.721257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044904</td>\n",
       "      <td>123.402262</td>\n",
       "      <td>3</td>\n",
       "      <td>0.717549</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  song_duration_ms  acousticness  danceability    energy  \\\n",
       "0  32823          144667.0      0.585599      0.691626  0.503891   \n",
       "1  16298          203954.0      0.016664      0.667695  0.683820   \n",
       "2  28505          179054.0      0.069471      0.624358  0.891436   \n",
       "3   6689          246074.0      0.333662      0.645299  0.716589   \n",
       "4  26893          282403.0      0.378221      0.258557  0.617000   \n",
       "\n",
       "   instrumentalness   key  liveness   loudness  audio_mode  speechiness  \\\n",
       "0          0.222360  10.0  0.115524 -11.642316           0     0.049854   \n",
       "1          0.001178   4.0  0.213299        NaN           1     0.102933   \n",
       "2          0.000637   2.0       NaN        NaN           1     0.173795   \n",
       "3          0.003159   2.0  0.114810  -9.178056           0     0.056690   \n",
       "4          0.001366   7.0  0.172308  -6.721257           0     0.044904   \n",
       "\n",
       "        tempo  time_signature  audio_valence  song_popularity  kfold  \n",
       "0   86.041825               3       0.539072                1      4  \n",
       "1   97.073546               3       0.667166                0      0  \n",
       "2  140.102334               4       0.824423                0      1  \n",
       "3  101.694474               4       0.532739                1      3  \n",
       "4  123.402262               3       0.717549                0      1  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold    \n",
    "    return df     \n",
    "\n",
    "df_train = strat_kfold_dataframe(df_train, target_col_name=Config.TARGET_COL_NAME, num_folds=Config.NUM_FOLDS)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['song_duration_ms', 'acousticness', 'danceability', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'audio_valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_col(df, cols_with_nulls):\n",
    "    for col_name in cols_with_nulls:        \n",
    "        df[col_name + \"_missing\"] = [int(item) for item in df[col_name].isna().values]\n",
    "    return df        \n",
    "\n",
    "train_cols_withnulls = [col for col in df_train.columns if df_train[col].isnull().any()]\n",
    "test_cols_withnulls = [col for col in df_test.columns if df_test[col].isnull().any()]\n",
    "df_train = add_missing_col(df_train, train_cols_withnulls)\n",
    "df_test = add_missing_col(df_test, test_cols_withnulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df_col(df, col_name, imputer):\n",
    "    imputed_col = imputer.fit_transform(df[col_name].to_numpy().reshape(-1, 1))\n",
    "    return pd.Series(imputed_col.reshape(-1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df, cols, col_type=\"cont\"):    \n",
    "    if col_type == \"cont\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    elif col_type == \"cat\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")            \n",
    "    for col in cols:\n",
    "        df[col] = impute_df_col(df, col, imputer)\n",
    "    return df\n",
    "\n",
    "df_train = impute_missing_values(df_train, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_train = impute_missing_values(df_train, cont_cols, col_type=\"cont\")\n",
    "df_test = impute_missing_values(df_test, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_test = impute_missing_values(df_test, cont_cols, col_type=\"cont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_train.columns if df_train[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_test.columns if df_test[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, prefix=Config.CATEGORICAL_COLS, columns=Config.CATEGORICAL_COLS)\n",
    "df_test = pd.get_dummies(df_test, prefix=Config.CATEGORICAL_COLS, columns=Config.CATEGORICAL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_int_encoding(df, col_name):\n",
    "    ordinal_encoder = category_encoders.OrdinalEncoder(cols=[col_name])\n",
    "    col_encoded = ordinal_encoder.fit_transform(df[col_name])\n",
    "    return col_encoded.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"key\"] = col_int_encoding(df_train, \"key\")\n",
    "# df_test[\"key\"] = col_int_encoding(df_test, \"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train[\"key\"].dtype)\n",
    "# print(df_test[\"key\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_features(df):\n",
    "    cols_to_leave = [\"id\", \"kfold\", \"song_popularity_proba\", Config.TARGET_COL_NAME]\n",
    "    col_names = [item for item in df.columns.values.tolist() if item not in cols_to_leave]    \n",
    "    return df[col_names]\n",
    "\n",
    "def get_fold_data(fold, df):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]    \n",
    "    X_train = get_input_features(df_train)\n",
    "    y_train = df_train[Config.TARGET_COL_NAME]\n",
    "    X_val = get_input_features(df_val)\n",
    "    y_val = df_val[Config.TARGET_COL_NAME]\n",
    "    return X_train, y_train, X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_leave = [\"id\", \"kfold\", \"song_popularity_proba\", Config.TARGET_COL_NAME]\n",
    "col_names = [item for item in df_train.columns.values.tolist() if item not in cols_to_leave]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_df, train_y, val_df, val_y, params=None, callbacks=None):\n",
    "    train_data = lgbm.Dataset(\n",
    "            data=train_df[col_names], label=train_y, feature_name=col_names#, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS\n",
    "        )\n",
    "    val_data = lgbm.Dataset(\n",
    "            data=val_df[col_names], label=val_y, feature_name=col_names, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS, \n",
    "            reference=train_data\n",
    "        )    \n",
    "    if callbacks is not None:        \n",
    "        model = lgbm.train(\n",
    "                    params,\n",
    "                    train_set=train_data,                \n",
    "                    valid_sets=val_data,\n",
    "                    verbose_eval=-1,\n",
    "                    callbacks=callbacks\n",
    "                )\n",
    "    else:\n",
    "        model = lgbm.train(\n",
    "                    params,\n",
    "                    train_set=train_data,                \n",
    "                    valid_sets=val_data,\n",
    "                    verbose_eval=-1\n",
    "                )       \n",
    "    val_preds = model.predict(val_df, num_iteration=model.best_iteration)    \n",
    "    auc = roc_auc_score(val_y, val_preds)\n",
    "    return auc, val_preds, model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params(train_df, train_y, params=None):\n",
    "    train_data = lgbm.Dataset(\n",
    "            data=train_df[col_names], label=train_y, feature_name=col_names#, \n",
    "            #categorical_feature=Config.CATEGORICAL_COLS\n",
    "        )   \n",
    "    lgbmtuner_cv = LightGBMTunerCV(\n",
    "        params,\n",
    "        train_set=train_data,        \n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        nfold=Config.NUM_FOLDS,\n",
    "        verbose_eval=-1\n",
    "    ) \n",
    "    lgbmtuner_cv.run()                \n",
    "    print(\"Best Params: \", lgbmtuner_cv.best_params)    \n",
    "    print(\"Best score: \", lgbmtuner_cv.best_score)    \n",
    "    return lgbmtuner_cv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         \"objective\": \"binary\",\n",
    "#         \"metric\": \"auc\",\n",
    "#         \"verbosity\": -1,\n",
    "#         \"boosting_type\": \"gbdt\",\n",
    "#     }\n",
    "\n",
    "# train_y = df_train[Config.TARGET_COL_NAME]\n",
    "# tuned_model = tune_params(df_train, train_y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# def rf_objective(trial):       \n",
    "#     params_dynamic = {        \n",
    "#         \"num_iterations\": int(trial.suggest_int(\"num_iterations\", 500, 10000)),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 100),        \n",
    "#     }\n",
    "#     params_static = {\n",
    "#         'objective': 'binary', \n",
    "#         'metric': 'auc', \n",
    "#         'verbose': -1, \n",
    "#         'boosting_type': 'gbdt', \n",
    "#         'feature_pre_filter': False, \n",
    "#         'lambda_l1': 9.439044618205312, \n",
    "#         'lambda_l2': 0.615750336486198, \n",
    "#         'num_leaves': 3, \n",
    "#         'feature_fraction': 0.62, \n",
    "#         'bagging_fraction': 0.5286479709465361, \n",
    "#         'bagging_freq': 1, \n",
    "#         'min_child_samples': 20,    \n",
    "#         \"cat_smooth\": 96,\n",
    "#         \"cat_l2\": 17,        \n",
    "#         \"early_stopping_round\": 500\n",
    "#         }\n",
    "#     params = {**params_dynamic, **params_static}\n",
    "#     #params[\"early_stopping_rounds\"] = int(params[\"n_estimators\"] * 0.1)    \n",
    "#     fold_auc = []\n",
    "#     # Add a callback for pruning.\n",
    "#     pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")    \n",
    "#     train_y = df_train[Config.TARGET_COL_NAME]\n",
    "#     train_data = lgbm.Dataset(data=df_train[col_names], label=train_y, feature_name=col_names) #, categorical_feature=Config.CATEGORICAL_COLS)\n",
    "#     result = lgbm.cv(\n",
    "#                 params,\n",
    "#                 train_set = train_data,\n",
    "#                 nfold = Config.NUM_FOLDS,\n",
    "#                 stratified = True,\n",
    "#                 shuffle = True,\n",
    "#                 seed = Config.RANDOM_SEED,\n",
    "#                 feature_name = col_names\n",
    "#                 #categorical_feature = Config.CATEGORICAL_COLS\n",
    "#             )\n",
    "#     #print(result)            \n",
    "#     mean_auc = np.mean(result[\"auc-mean\"])\n",
    "#     return mean_auc\n",
    "\n",
    "# study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\", study_name=\"LGBMModelTuning\")    \n",
    "# study.optimize(rf_objective, n_trials=20)\n",
    "# print(\"Best trial:\")\n",
    "# print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params1 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbosity': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 3.5832756412408226e-05, \n",
    "    'lambda_l2': 7.499744130226807, \n",
    "    'num_leaves': 2, \n",
    "    'feature_fraction': 0.8, \n",
    "    'bagging_fraction': 0.9969384880158432, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 20, \n",
    "    'num_iterations': 1000, \n",
    "    'early_stopping_round': None, \n",
    "    'categorical_column': [5, 8, 11]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMTunerCV with 5 folds\n",
    "model_params3 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 7.994567596327698, \n",
    "    'lambda_l2': 0.04882156030098934, \n",
    "    'num_leaves': 2, \n",
    "    'feature_fraction': 0.48000000000000004, \n",
    "    'bagging_fraction': 0.957852828579762, \n",
    "    'bagging_freq': 5, \n",
    "    'min_child_samples': 100,\n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning with LightGBMTunerCV\n",
    "\n",
    "model_params2 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 9.439044618205312, \n",
    "    'lambda_l2': 0.615750336486198, \n",
    "    'num_leaves': 3, \n",
    "    'feature_fraction': 0.62, \n",
    "    'bagging_fraction': 0.5286479709465361, \n",
    "    'bagging_freq': 1, \n",
    "    'min_child_samples': 20,    \n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 500\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params4 = {\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'verbose': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 1.8963776746935667e-06, \n",
    "    'lambda_l2': 9.579973179083996, \n",
    "    'num_leaves': 3, \n",
    "    'feature_fraction': 0.7, \n",
    "    'bagging_fraction': 0.7684172265445463, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 20,\n",
    "    'num_iterations': 10000,\n",
    "    \"early_stopping_round\": 800,\n",
    "    \"learning_rate\": 0.01\n",
    "    }\n",
    "\n",
    "#Best score:  0.5740860150826701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5088]\tvalid_0's auc: 0.573621\n",
      "fold 0 auc score = 0.5736209863592064\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7914]\tvalid_0's auc: 0.571415\n",
      "fold 1 auc score = 0.5714154738232213\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2826]\tvalid_0's auc: 0.579844\n",
      "fold 2 auc score = 0.5798443273948367\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2038]\tvalid_0's auc: 0.580331\n",
      "fold 3 auc score = 0.5803313482124637\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3684]\tvalid_0's auc: 0.576271\n",
      "fold 4 auc score = 0.5762711772930507\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = []\n",
    "test_preds = {}\n",
    "df_train[\"song_popularity_proba\"] = 0.0\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    train_df, train_y, val_df, val_y = get_fold_data(fold, df_train) \n",
    "    test_df = get_input_features(df_test)       \n",
    "    fold_auc_score, fold_val_preds, model = run_training(train_df, train_y, val_df, val_y, params=model_params4)\n",
    "    print(f\"fold {fold } auc score = {fold_auc_score}\")\n",
    "    # add the validation probability predictions for the fold to a new column in train data\n",
    "    df_train.loc[df_train.kfold == fold, \"song_popularity_proba\"] = fold_val_preds    \n",
    "    fold_test_preds = model.predict(test_df, num_iteration=model.best_iteration)\n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds \n",
    "    fold_metrics_model.append((round(fold_auc_score, 6), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc scores = [0.573367, 0.571255, 0.581349, 0.580906, 0.576361]\n",
      "mean auc across folds = 0.5766476, auc stdev across folds = 0.004476654532125554\n"
     ]
    }
   ],
   "source": [
    "fold_metrics = [item[0] for item in fold_metrics_model]\n",
    "print(f\"auc scores = {fold_metrics}\")    \n",
    "cv_auc_mean = statistics.mean(fold_metrics)\n",
    "cv_auc_stdev = statistics.stdev(fold_metrics)\n",
    "print(f\"mean auc across folds = {cv_auc_mean}, auc stdev across folds = {cv_auc_stdev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 10000 test rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.443620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.462369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.278161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.292563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.358876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  song_popularity\n",
       "0   0         0.443620\n",
       "1   1         0.462369\n",
       "2   2         0.278161\n",
       "3   3         0.292563\n",
       "4   4         0.358876"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "test_pred_cols = [f\"fold_{fold}_test_preds\" for fold in range(Config.NUM_FOLDS)]\n",
    "df_test_preds[\"mean_test_pred\"] = df_test_preds[test_pred_cols].mean(axis=1)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")\n",
    "df_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "df_submission['song_popularity']= df_test_preds[\"mean_test_pred\"]\n",
    "df_submission.to_csv('submission_lgbm.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation predictions for all folds to csv\n"
     ]
    }
   ],
   "source": [
    "lgbm_val_preds = df_train[[\"id\", \"song_popularity_proba\", \"song_popularity\"]]\n",
    "lgbm_val_preds.to_csv(\"lgbm_val_preds.csv\")\n",
    "print(\"Saved validation predictions for all folds to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.508618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.515870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>0.504178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>0.503326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>0.555047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>9839</td>\n",
       "      <td>0.502612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>9866</td>\n",
       "      <td>0.540699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9972</td>\n",
       "      <td>0.527604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9983</td>\n",
       "      <td>0.507024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9988</td>\n",
       "      <td>0.529551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  song_popularity\n",
       "39      39         0.508618\n",
       "97      97         0.515870\n",
       "130    130         0.504178\n",
       "171    171         0.503326\n",
       "254    254         0.555047\n",
       "...    ...              ...\n",
       "9839  9839         0.502612\n",
       "9866  9866         0.540699\n",
       "9972  9972         0.527604\n",
       "9983  9983         0.507024\n",
       "9988  9988         0.529551\n",
       "\n",
       "[212 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission[df_submission.song_popularity > 0.5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0197751694b00855cd01780d565fa2e16f7945f624c4146f8d6aac863c2ba178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
