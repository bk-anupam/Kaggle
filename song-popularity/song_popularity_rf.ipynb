{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 13\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"song_popularity\"\n",
    "    CATEGORICAL_COLS = [\"audio_mode\", \"time_signature\", \"key\"]\n",
    "\n",
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>audio_mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>audio_valence</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37020</td>\n",
       "      <td>241605.0</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.668579</td>\n",
       "      <td>0.940644</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.660077</td>\n",
       "      <td>-5.334750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098402</td>\n",
       "      <td>145.488755</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752138</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136844</td>\n",
       "      <td>0.857481</td>\n",
       "      <td>0.780121</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.200062</td>\n",
       "      <td>-12.289020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>122.209006</td>\n",
       "      <td>3</td>\n",
       "      <td>0.747739</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15625</td>\n",
       "      <td>181809.0</td>\n",
       "      <td>0.176350</td>\n",
       "      <td>0.722215</td>\n",
       "      <td>0.904362</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.094481</td>\n",
       "      <td>-4.299832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>119.554958</td>\n",
       "      <td>4</td>\n",
       "      <td>0.648478</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10671</td>\n",
       "      <td>167442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354930</td>\n",
       "      <td>0.496588</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.112777</td>\n",
       "      <td>-13.174818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>106.928615</td>\n",
       "      <td>3</td>\n",
       "      <td>0.531688</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4393</td>\n",
       "      <td>164342.0</td>\n",
       "      <td>0.112951</td>\n",
       "      <td>0.633773</td>\n",
       "      <td>0.922505</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.141997</td>\n",
       "      <td>-5.169450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>126.757199</td>\n",
       "      <td>4</td>\n",
       "      <td>0.661839</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  song_duration_ms  acousticness  danceability    energy  \\\n",
       "0  37020          241605.0      0.043564      0.668579  0.940644   \n",
       "1   5531               NaN      0.136844      0.857481  0.780121   \n",
       "2  15625          181809.0      0.176350      0.722215  0.904362   \n",
       "3  10671          167442.0           NaN      0.354930  0.496588   \n",
       "4   4393          164342.0      0.112951      0.633773  0.922505   \n",
       "\n",
       "   instrumentalness  key  liveness   loudness  audio_mode  speechiness  \\\n",
       "0          0.001371  5.0  0.660077  -5.334750           1     0.098402   \n",
       "1          0.003005  5.0  0.200062 -12.289020           0     0.040943   \n",
       "2          0.000554  8.0  0.094481  -4.299832           0     0.061723   \n",
       "3          0.000845  8.0  0.112777 -13.174818           0     0.042100   \n",
       "4          0.004053  5.0  0.141997  -5.169450           0     0.036036   \n",
       "\n",
       "        tempo  time_signature  audio_valence  song_popularity  kfold  \n",
       "0  145.488755               3       0.752138                0      4  \n",
       "1  122.209006               3       0.747739                1      4  \n",
       "2  119.554958               4       0.648478                0      2  \n",
       "3  106.928615               3       0.531688                1      2  \n",
       "4  126.757199               4       0.661839                0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold    \n",
    "    return df     \n",
    "\n",
    "df_train = strat_kfold_dataframe(df_train, target_col_name=Config.TARGET_COL_NAME)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['song_duration_ms', 'acousticness', 'danceability', 'energy', \n",
    "            'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'audio_valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df_col(df, col_name, imputer):\n",
    "    imputed_col = imputer.fit_transform(df[col_name].to_numpy().reshape(-1, 1))\n",
    "    return pd.Series(imputed_col.reshape(-1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df, cols, col_type=\"cont\"):    \n",
    "    if col_type == \"cont\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    elif col_type == \"cat\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")            \n",
    "    for col in cols:\n",
    "        df[col] = impute_df_col(df, col, imputer)\n",
    "    return df\n",
    "\n",
    "df_train = impute_missing_values(df_train, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_train = impute_missing_values(df_train, cont_cols, col_type=\"cont\")\n",
    "df_test = impute_missing_values(df_test, Config.CATEGORICAL_COLS, col_type=\"cat\")\n",
    "df_test = impute_missing_values(df_test, cont_cols, col_type=\"cont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_col(df, cols_with_nulls):\n",
    "    for col_name in cols_with_nulls:        \n",
    "        df[col_name + \"_missing\"] = [int(item) for item in df[col_name].isna().values]\n",
    "    return df        \n",
    "\n",
    "train_cols_withnulls = [col for col in df_train.columns if df_train[col].isnull().any()]\n",
    "test_cols_withnulls = [col for col in df_test.columns if df_test[col].isnull().any()]\n",
    "df_train = add_missing_col(df_train, train_cols_withnulls)\n",
    "df_test = add_missing_col(df_test, test_cols_withnulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_train.columns if df_train[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_test.columns if df_test[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_one_hot_encode(df, cols):    \n",
    "    one_hot_enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    one_hot_enc.fit(df[cols])\n",
    "    return one_hot_enc.transform(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_features(df):\n",
    "    non_cont_cols = Config.CATEGORICAL_COLS + [\"id\", \"kfold\", \"song_popularity_proba\", Config.TARGET_COL_NAME]\n",
    "    cont_col_names = [item for item in df.columns.values.tolist() if item not in non_cont_cols]     \n",
    "    X_cont = df[cont_col_names].to_numpy()       \n",
    "    X_cat_one_hot = col_one_hot_encode(df, Config.CATEGORICAL_COLS)    \n",
    "    X = np.concatenate((X_cont, X_cat_one_hot), axis=1)    \n",
    "    return X\n",
    "\n",
    "def get_fold_data(fold, df):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]\n",
    "    X_train = get_input_features(df_train)\n",
    "    y_train = df_train[Config.TARGET_COL_NAME].to_numpy()\n",
    "    X_val = get_input_features(df_val)\n",
    "    y_val = df_val[Config.TARGET_COL_NAME].to_numpy()\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_X, train_y, val_X, val_y):        \n",
    "    scaler = StandardScaler()\n",
    "    train_X_scaled = scaler.fit_transform(train_X)    \n",
    "    val_X_scaled = scaler.fit_transform(val_X)    \n",
    "    model.fit(train_X_scaled, train_y.ravel())\n",
    "    val_y_pred_proba = model.predict_proba(val_X_scaled)\n",
    "    auc = roc_auc_score(val_y, val_y_pred_proba[:, 1], average=\"weighted\")\n",
    "    return auc, model, val_y_pred_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-28 18:28:23,682]\u001b[0m A new study created in memory with name: RFModelTuning\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:28:37,402]\u001b[0m Trial 0 finished with value: 0.5682960497746609 and parameters: {'n_estimators': 155, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 0 with value: 0.5682960497746609.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:29:12,767]\u001b[0m Trial 1 finished with value: 0.5664979216554858 and parameters: {'n_estimators': 751, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 0 with value: 0.5682960497746609.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:29:43,111]\u001b[0m Trial 2 finished with value: 0.571596434633612 and parameters: {'n_estimators': 703, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:30:18,230]\u001b[0m Trial 3 finished with value: 0.5714305311218595 and parameters: {'n_estimators': 708, 'max_depth': 13, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:30:45,331]\u001b[0m Trial 4 finished with value: 0.5710129184399158 and parameters: {'n_estimators': 628, 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 8, 'max_features': 'auto'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:31:03,838]\u001b[0m Trial 5 finished with value: 0.5706685603845274 and parameters: {'n_estimators': 405, 'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 8, 'max_features': 'auto'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:31:21,361]\u001b[0m Trial 6 finished with value: 0.5697962663479242 and parameters: {'n_estimators': 318, 'max_depth': 17, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:31:28,186]\u001b[0m Trial 7 finished with value: 0.5698443277396471 and parameters: {'n_estimators': 132, 'max_depth': 11, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'auto'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:31:47,852]\u001b[0m Trial 8 finished with value: 0.5663862756385821 and parameters: {'n_estimators': 705, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:32:26,078]\u001b[0m Trial 9 finished with value: 0.5688910911967756 and parameters: {'n_estimators': 671, 'max_depth': 18, 'min_samples_leaf': 2, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:33:19,916]\u001b[0m Trial 10 finished with value: 0.5707311690442775 and parameters: {'n_estimators': 918, 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'auto'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:34:02,052]\u001b[0m Trial 11 finished with value: 0.5714979052424012 and parameters: {'n_estimators': 903, 'max_depth': 14, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:34:49,394]\u001b[0m Trial 12 finished with value: 0.5711435086897676 and parameters: {'n_estimators': 992, 'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:35:20,476]\u001b[0m Trial 13 finished with value: 0.5706850746544554 and parameters: {'n_estimators': 847, 'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:35:50,807]\u001b[0m Trial 14 finished with value: 0.569051865247336 and parameters: {'n_estimators': 525, 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:36:31,186]\u001b[0m Trial 15 finished with value: 0.5707740723731506 and parameters: {'n_estimators': 832, 'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:36:49,143]\u001b[0m Trial 16 finished with value: 0.5692863381639313 and parameters: {'n_estimators': 534, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:37:27,812]\u001b[0m Trial 17 finished with value: 0.5715587040641159 and parameters: {'n_estimators': 821, 'max_depth': 11, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:38:08,495]\u001b[0m Trial 18 finished with value: 0.5713956999237829 and parameters: {'n_estimators': 791, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 4, 'max_features': 'auto'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n",
      "\u001b[32m[I 2022-01-28 18:38:34,997]\u001b[0m Trial 19 finished with value: 0.5713290536520373 and parameters: {'n_estimators': 601, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.571596434633612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'n_estimators': 703, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def rf_objective(trial):       \n",
    "    params = {        \n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\", [1, 2, 4]),\n",
    "        \"min_samples_split\": trial.suggest_categorical(\"min_samples_split\", [2, 4, 8]),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"log2\"])\n",
    "    }\n",
    "    rf_model = RandomForestClassifier(\n",
    "                n_estimators=params[\"n_estimators\"],                 \n",
    "                max_depth=params[\"max_depth\"],\n",
    "                min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                min_samples_split=params[\"min_samples_split\"],\n",
    "                max_features=params[\"max_features\"],\n",
    "                random_state=Config.RANDOM_SEED,\n",
    "                n_jobs=-1\n",
    "            )   \n",
    "\n",
    "    fold_auc = []\n",
    "    for fold in range(Config.NUM_FOLDS):\n",
    "        train_X, train_y, val_X, val_y = get_fold_data(fold, df_train)\n",
    "        auc_score, _, _ = run_training(rf_model, train_X, train_y, val_X, val_y)\n",
    "        fold_auc.append(auc_score)\n",
    "    mean_auc = statistics.mean(fold_auc)                \n",
    "    return mean_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"RFModelTuning\")    \n",
    "study.optimize(rf_objective, n_trials=20)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial:\n",
    "# {'n_estimators': 703, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 4, 'max_features': 'log2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model_params = {\"n_estimators\": 600, \"random_state\": 42, \"max_depth\": 8}\n",
    "rf_model_params = study.best_params\n",
    "rf_model = RandomForestClassifier(\n",
    "                n_estimators=rf_model_params[\"n_estimators\"],                 \n",
    "                max_depth=rf_model_params[\"max_depth\"],\n",
    "                min_samples_leaf=rf_model_params[\"min_samples_leaf\"],\n",
    "                min_samples_split=rf_model_params[\"min_samples_split\"],\n",
    "                max_features=rf_model_params[\"max_features\"],\n",
    "                random_state=Config.RANDOM_SEED,\n",
    "                n_jobs=-1\n",
    "            )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 auc score = 0.5717816670630163\n",
      "fold 1 auc score = 0.5778660203639332\n",
      "fold 2 auc score = 0.5711537144697939\n",
      "fold 3 auc score = 0.567197775045496\n",
      "fold 4 auc score = 0.5699829962258205\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = []\n",
    "test_preds = {}\n",
    "df_train[\"song_popularity_proba\"] = 0.0\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    X_train, y_train, X_val, y_val = get_fold_data(fold, df_train)\n",
    "    fold_auc_score, model, fold_val_preds = run_training(rf_model, X_train, y_train, X_val, y_val)\n",
    "    print(f\"fold {fold } auc score = {fold_auc_score}\")\n",
    "    # add the validation probability predictions for the fold to a new column in train data\n",
    "    df_train[df_train.kfold == fold][\"song_popularity_proba\"] = fold_val_preds    \n",
    "    X_test = get_input_features(df_test)\n",
    "    scaler = StandardScaler()\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    fold_test_preds = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds    \n",
    "    fold_metrics_model.append((round(fold_auc_score, 4), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc scores = [0.5718, 0.5779, 0.5712, 0.5672, 0.57]\n",
      "mean auc across folds = 0.57162, auc stdev across folds = 0.003930903204099517\n"
     ]
    }
   ],
   "source": [
    "fold_metrics = [item[0] for item in fold_metrics_model]\n",
    "print(f\"auc scores = {fold_metrics}\")    \n",
    "cv_auc_mean = statistics.mean(fold_metrics)\n",
    "cv_auc_stdev = statistics.stdev(fold_metrics)\n",
    "print(f\"mean auc across folds = {cv_auc_mean}, auc stdev across folds = {cv_auc_stdev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 10000 test rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.369985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.336024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.347541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.365547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  song_popularity\n",
       "0   0         0.369985\n",
       "1   1         0.420580\n",
       "2   2         0.336024\n",
       "3   3         0.347541\n",
       "4   4         0.365547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "test_pred_cols = [f\"fold_{fold}_test_preds\" for fold in range(Config.NUM_FOLDS)]\n",
    "df_test_preds[\"mean_test_pred\"] = df_test_preds[test_pred_cols].mean(axis=1)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")\n",
    "df_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "df_submission['song_popularity']= df_test_preds[\"mean_test_pred\"]\n",
    "df_submission.to_csv('submission_rf.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.512736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>1558</td>\n",
       "      <td>0.501997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>2344</td>\n",
       "      <td>0.514235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>2958</td>\n",
       "      <td>0.528304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>4028</td>\n",
       "      <td>0.500179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>4161</td>\n",
       "      <td>0.505733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>4629</td>\n",
       "      <td>0.511304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>5146</td>\n",
       "      <td>0.543439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>5777</td>\n",
       "      <td>0.508473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>6204</td>\n",
       "      <td>0.514941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>6792</td>\n",
       "      <td>0.513231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>7726</td>\n",
       "      <td>0.506817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>8719</td>\n",
       "      <td>0.517405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>9416</td>\n",
       "      <td>0.504303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>9700</td>\n",
       "      <td>0.544719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  song_popularity\n",
       "1003  1003         0.512736\n",
       "1558  1558         0.501997\n",
       "2344  2344         0.514235\n",
       "2958  2958         0.528304\n",
       "4028  4028         0.500179\n",
       "4161  4161         0.505733\n",
       "4629  4629         0.511304\n",
       "5146  5146         0.543439\n",
       "5777  5777         0.508473\n",
       "6204  6204         0.514941\n",
       "6792  6792         0.513231\n",
       "7726  7726         0.506817\n",
       "8719  8719         0.517405\n",
       "9416  9416         0.504303\n",
       "9700  9700         0.544719"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission[df_submission.song_popularity > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation predictions for all folds to csv\n"
     ]
    }
   ],
   "source": [
    "rf_val_preds = df_train[[\"id\", \"song_popularity_proba\", \"song_popularity\"]]\n",
    "rf_val_preds.to_csv(\"rf_val_preds.csv\")\n",
    "print(\"Saved validation predictions for all folds to csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0197751694b00855cd01780d565fa2e16f7945f624c4146f8d6aac863c2ba178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
